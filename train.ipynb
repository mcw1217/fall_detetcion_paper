{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (41, 30, 49)\n",
      "2 (35, 30, 49)\n",
      "3 (32, 30, 49)\n",
      "4 (37, 30, 49)\n",
      "5 (41, 30, 49)\n",
      "6 (36, 30, 49)\n",
      "7 (32, 30, 49)\n",
      "8 (37, 30, 49)\n",
      "9 (5, 30, 49)\n",
      "10 (17, 30, 49)\n",
      "11 (28, 30, 49)\n",
      "12 (28, 30, 49)\n",
      "13 (18, 30, 49)\n",
      "14 (14, 30, 49)\n",
      "15 (26, 30, 49)\n",
      "16 (28, 30, 49)\n",
      "17 (22, 30, 49)\n",
      "18 (21, 30, 49)\n",
      "19 (46, 30, 49)\n",
      "20 (42, 30, 49)\n",
      "21 (41, 30, 49)\n",
      "22 (33, 30, 49)\n",
      "23 (38, 30, 49)\n",
      "24 (40, 30, 49)\n",
      "25 (36, 30, 49)\n",
      "26 (48, 30, 49)\n",
      "27 (46, 30, 49)\n",
      "28 (50, 30, 49)\n",
      "29 (50, 30, 49)\n",
      "30 (41, 30, 49)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,31):\n",
    "    print(i,np.load(f\"./dataset/seq_fall-2023-{i}.npy\").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10702, 30, 49)\n"
     ]
    }
   ],
   "source": [
    "actions = [\n",
    "    'fall','stand','walking','lie'\n",
    "]\n",
    "data = np.load(\"dataset/seq_fall-2023-1.npy\")\n",
    "datas = np.load(\"dataset/seq_stand-2023-1.npy\")\n",
    "datas2 = np.load(\"dataset/seq_walking-2023-1.npy\")\n",
    "datas3 = np.load(\"dataset/seq_lie-2023-1.npy\")\n",
    "for i in range(2,60):\n",
    "    data = np.concatenate([\n",
    "        data,\n",
    "        np.load(f'dataset/seq_fall-2023-{i}.npy')\n",
    "    ], axis=0)  \n",
    "# for i in range(2,3):\n",
    "#     datas = np.concatenate([\n",
    "#         datas,\n",
    "#         np.load(f'dataset/seq_stand-2023-{i}.npy')\n",
    "#     ], axis=0)\n",
    "    \n",
    "for i in range(2,3):\n",
    "    data = np.concatenate([\n",
    "        data,\n",
    "        np.load(f'dataset/seq_walking-2023-{i}.npy')\n",
    "    ], axis=0)\n",
    "    \n",
    "for i in range(2,5):\n",
    "    data = np.concatenate([\n",
    "        data,\n",
    "        np.load(f'dataset/seq_lie-2023-{i}.npy')\n",
    "    ], axis=0) \n",
    "        \n",
    "data = np.concatenate([data,datas])\n",
    "data = np.concatenate([data,datas2])\n",
    "data = np.concatenate([data,datas3])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.load(\"dataset/seq_fall-2023-1.npy\")\n",
    "# datas = np.load(\"dataset/seq_stand-2023-1.npy\")\n",
    "# datas2 = np.load(\"dataset/seq_walking-2023-1.npy\")\n",
    "# datas3 = np.load(\"dataset/seq_lie-2023-1.npy\")\n",
    "\n",
    "\n",
    "# for i in range(2,60):\n",
    "#     data = np.concatenate([\n",
    "#         data,\n",
    "#         np.load(f'dataset/seq_fall-2023-{i}.npy')\n",
    "#     ], axis=0)  \n",
    "# print(data.shape)\n",
    "\n",
    "# # fall = 1569\n",
    "# # walking = 2428\n",
    "# # lie = 5710\n",
    "# for i in range(2,5):\n",
    "#     datas3 = np.concatenate([\n",
    "#         datas3,\n",
    "#         np.load(f'dataset/seq_lie-2023-{i}.npy')\n",
    "#     ], axis=0) \n",
    "\n",
    "# print(datas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10702, 30, 48)\n",
      "(10702,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)\n",
    "print(labels[700:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10702, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7491, 30, 48) (7491, 4)\n",
      "(3211, 30, 48) (3211, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.3,random_state=4220)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 48)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 30)                7200      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 30)                930       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 124       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,254\n",
      "Trainable params: 8,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense,GRU,Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    GRU(30,dropout=0.2,activation='relu',input_shape=x_train.shape[1:3]),\n",
    "    # GRU(32,dropout=0.3),\n",
    "    # Dropout(0.2),\n",
    "    Dense(30, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "234/235 [============================>.] - ETA: 0s - loss: 1.1988 - acc: 0.6389\n",
      "Epoch 1: val_loss improved from inf to 1.02803, saving model to models\\model.h5\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 1.1985 - acc: 0.6390 - val_loss: 1.0280 - val_acc: 0.6708 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "234/235 [============================>.] - ETA: 0s - loss: 0.4367 - acc: 0.8518\n",
      "Epoch 2: val_loss improved from 1.02803 to 0.65633, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4366 - acc: 0.8518 - val_loss: 0.6563 - val_acc: 0.7269 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 0.2481 - acc: 0.9199\n",
      "Epoch 3: val_loss improved from 0.65633 to 0.54980, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.2481 - acc: 0.9195 - val_loss: 0.5498 - val_acc: 0.7783 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 0.1701 - acc: 0.9423\n",
      "Epoch 4: val_loss improved from 0.54980 to 0.43553, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1674 - acc: 0.9429 - val_loss: 0.4355 - val_acc: 0.8054 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 0.1246 - acc: 0.9584\n",
      "Epoch 5: val_loss improved from 0.43553 to 0.23133, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1235 - acc: 0.9589 - val_loss: 0.2313 - val_acc: 0.9187 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "225/235 [===========================>..] - ETA: 0s - loss: 0.0794 - acc: 0.9758\n",
      "Epoch 6: val_loss improved from 0.23133 to 0.16660, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0780 - acc: 0.9764 - val_loss: 0.1666 - val_acc: 0.9477 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "233/235 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9811\n",
      "Epoch 7: val_loss improved from 0.16660 to 0.10003, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0657 - acc: 0.9810 - val_loss: 0.1000 - val_acc: 0.9782 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9840\n",
      "Epoch 8: val_loss improved from 0.10003 to 0.08366, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0534 - acc: 0.9842 - val_loss: 0.0837 - val_acc: 0.9816 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9877\n",
      "Epoch 9: val_loss did not improve from 0.08366\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0375 - acc: 0.9879 - val_loss: 0.1146 - val_acc: 0.9586 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 0.0327 - acc: 0.9902\n",
      "Epoch 10: val_loss improved from 0.08366 to 0.07345, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0324 - acc: 0.9901 - val_loss: 0.0735 - val_acc: 0.9838 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9910\n",
      "Epoch 11: val_loss did not improve from 0.07345\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0270 - acc: 0.9909 - val_loss: 0.1042 - val_acc: 0.9710 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 0.0215 - acc: 0.9934\n",
      "Epoch 12: val_loss improved from 0.07345 to 0.02690, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0212 - acc: 0.9935 - val_loss: 0.0269 - val_acc: 0.9919 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.0284 - acc: 0.9915\n",
      "Epoch 13: val_loss did not improve from 0.02690\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0284 - acc: 0.9915 - val_loss: 0.0379 - val_acc: 0.9897 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9956\n",
      "Epoch 14: val_loss improved from 0.02690 to 0.02652, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0173 - acc: 0.9956 - val_loss: 0.0265 - val_acc: 0.9944 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 0.0172 - acc: 0.9959\n",
      "Epoch 15: val_loss improved from 0.02652 to 0.02437, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0168 - acc: 0.9959 - val_loss: 0.0244 - val_acc: 0.9956 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9969\n",
      "Epoch 16: val_loss did not improve from 0.02437\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0107 - acc: 0.9969 - val_loss: 0.0268 - val_acc: 0.9931 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9952\n",
      "Epoch 17: val_loss improved from 0.02437 to 0.02406, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0141 - acc: 0.9952 - val_loss: 0.0241 - val_acc: 0.9956 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 0.0151 - acc: 0.9950\n",
      "Epoch 18: val_loss did not improve from 0.02406\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0153 - acc: 0.9951 - val_loss: 0.0917 - val_acc: 0.9695 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 0.0244 - acc: 0.9933\n",
      "Epoch 19: val_loss did not improve from 0.02406\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0249 - acc: 0.9932 - val_loss: 0.0391 - val_acc: 0.9888 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 0.0111 - acc: 0.9968\n",
      "Epoch 20: val_loss improved from 0.02406 to 0.01271, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0112 - acc: 0.9968 - val_loss: 0.0127 - val_acc: 0.9953 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9937\n",
      "Epoch 21: val_loss did not improve from 0.01271\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0239 - acc: 0.9939 - val_loss: 0.0252 - val_acc: 0.9919 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9955\n",
      "Epoch 22: val_loss did not improve from 0.01271\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0162 - acc: 0.9956 - val_loss: 0.0361 - val_acc: 0.9872 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "234/235 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9968\n",
      "Epoch 23: val_loss improved from 0.01271 to 0.01192, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0113 - acc: 0.9968 - val_loss: 0.0119 - val_acc: 0.9966 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "234/235 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9984\n",
      "Epoch 24: val_loss did not improve from 0.01192\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0164 - val_acc: 0.9960 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 0.0045 - acc: 0.9986\n",
      "Epoch 25: val_loss improved from 0.01192 to 0.00986, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0044 - acc: 0.9987 - val_loss: 0.0099 - val_acc: 0.9984 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 0.0096 - acc: 0.9971\n",
      "Epoch 26: val_loss did not improve from 0.00986\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0094 - acc: 0.9972 - val_loss: 0.0121 - val_acc: 0.9969 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9979\n",
      "Epoch 27: val_loss improved from 0.00986 to 0.00973, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0090 - acc: 0.9980 - val_loss: 0.0097 - val_acc: 0.9988 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "233/235 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9992\n",
      "Epoch 28: val_loss improved from 0.00973 to 0.00706, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0023 - acc: 0.9992 - val_loss: 0.0071 - val_acc: 0.9978 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9973\n",
      "Epoch 29: val_loss did not improve from 0.00706\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0082 - acc: 0.9971 - val_loss: 0.0723 - val_acc: 0.9773 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9956\n",
      "Epoch 30: val_loss did not improve from 0.00706\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0128 - acc: 0.9957 - val_loss: 0.0124 - val_acc: 0.9969 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9970\n",
      "Epoch 31: val_loss did not improve from 0.00706\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0081 - acc: 0.9969 - val_loss: 0.0207 - val_acc: 0.9903 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "225/235 [===========================>..] - ETA: 0s - loss: 0.0164 - acc: 0.9957\n",
      "Epoch 32: val_loss did not improve from 0.00706\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0163 - acc: 0.9957 - val_loss: 0.0291 - val_acc: 0.9879 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9958\n",
      "Epoch 33: val_loss did not improve from 0.00706\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0120 - acc: 0.9959 - val_loss: 0.0167 - val_acc: 0.9925 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "233/235 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9989\n",
      "Epoch 34: val_loss improved from 0.00706 to 0.00454, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0031 - acc: 0.9989 - val_loss: 0.0045 - val_acc: 0.9984 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9995\n",
      "Epoch 35: val_loss did not improve from 0.00454\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0115 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 0.0044 - acc: 0.9989\n",
      "Epoch 36: val_loss did not improve from 0.00454\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0043 - acc: 0.9989 - val_loss: 0.0163 - val_acc: 0.9950 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "233/235 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9964\n",
      "Epoch 37: val_loss did not improve from 0.00454\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0127 - acc: 0.9964 - val_loss: 0.0311 - val_acc: 0.9900 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9992\n",
      "Epoch 38: val_loss did not improve from 0.00454\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0032 - acc: 0.9989 - val_loss: 0.0282 - val_acc: 0.9885 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9977\n",
      "Epoch 39: val_loss did not improve from 0.00454\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0078 - acc: 0.9977 - val_loss: 0.0408 - val_acc: 0.9819 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9959\n",
      "Epoch 40: val_loss did not improve from 0.00454\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0127 - acc: 0.9960 - val_loss: 0.0093 - val_acc: 0.9969 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9997\n",
      "Epoch 41: val_loss did not improve from 0.00454\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0197 - val_acc: 0.9919 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9997\n",
      "Epoch 42: val_loss did not improve from 0.00454\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0094 - val_acc: 0.9960 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9996\n",
      "Epoch 43: val_loss did not improve from 0.00454\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0094 - val_acc: 0.9947 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9965\n",
      "Epoch 44: val_loss did not improve from 0.00454\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0119 - acc: 0.9965 - val_loss: 0.0300 - val_acc: 0.9938 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9960\n",
      "Epoch 45: val_loss did not improve from 0.00454\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0116 - acc: 0.9961 - val_loss: 0.0124 - val_acc: 0.9969 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9977\n",
      "Epoch 46: val_loss did not improve from 0.00454\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0072 - acc: 0.9977 - val_loss: 0.0134 - val_acc: 0.9960 - lr: 0.0010\n",
      "Epoch 47/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9990\n",
      "Epoch 47: val_loss improved from 0.00454 to 0.00162, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0016 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 48/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 9.8498e-04 - acc: 0.9996\n",
      "Epoch 48: val_loss did not improve from 0.00162\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 9.7112e-04 - acc: 0.9996 - val_loss: 0.0040 - val_acc: 0.9997 - lr: 0.0010\n",
      "Epoch 49/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 0.0064 - acc: 0.9976\n",
      "Epoch 49: val_loss did not improve from 0.00162\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0064 - acc: 0.9976 - val_loss: 0.0583 - val_acc: 0.9857 - lr: 0.0010\n",
      "Epoch 50/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9976\n",
      "Epoch 50: val_loss did not improve from 0.00162\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0084 - acc: 0.9975 - val_loss: 0.0075 - val_acc: 0.9981 - lr: 0.0010\n",
      "Epoch 51/500\n",
      "233/235 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9983\n",
      "Epoch 51: val_loss did not improve from 0.00162\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0064 - acc: 0.9983 - val_loss: 0.0041 - val_acc: 0.9991 - lr: 0.0010\n",
      "Epoch 52/500\n",
      "234/235 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9988\n",
      "Epoch 52: val_loss did not improve from 0.00162\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0080 - val_acc: 0.9978 - lr: 0.0010\n",
      "Epoch 53/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9980\n",
      "Epoch 53: val_loss did not improve from 0.00162\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0064 - acc: 0.9980 - val_loss: 0.0134 - val_acc: 0.9944 - lr: 0.0010\n",
      "Epoch 54/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 6.5856e-04 - acc: 1.0000\n",
      "Epoch 54: val_loss did not improve from 0.00162\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 6.4470e-04 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 0.9966 - lr: 0.0010\n",
      "Epoch 55/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 1.7409e-04 - acc: 1.0000\n",
      "Epoch 55: val_loss did not improve from 0.00162\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.7024e-04 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9984 - lr: 0.0010\n",
      "Epoch 56/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9985\n",
      "Epoch 56: val_loss did not improve from 0.00162\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0059 - val_acc: 0.9972 - lr: 0.0010\n",
      "Epoch 57/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9977\n",
      "Epoch 57: val_loss did not improve from 0.00162\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0056 - acc: 0.9977 - val_loss: 0.0093 - val_acc: 0.9978 - lr: 0.0010\n",
      "Epoch 58/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9967\n",
      "Epoch 58: val_loss did not improve from 0.00162\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0123 - acc: 0.9968 - val_loss: 0.0306 - val_acc: 0.9894 - lr: 0.0010\n",
      "Epoch 59/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9996 \n",
      "Epoch 59: val_loss did not improve from 0.00162\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0333 - val_acc: 0.9885 - lr: 0.0010\n",
      "Epoch 60/500\n",
      "233/235 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9993\n",
      "Epoch 60: val_loss did not improve from 0.00162\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0018 - acc: 0.9993 - val_loss: 0.0023 - val_acc: 0.9994 - lr: 0.0010\n",
      "Epoch 61/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9972\n",
      "Epoch 61: val_loss did not improve from 0.00162\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0130 - acc: 0.9972 - val_loss: 0.0282 - val_acc: 0.9900 - lr: 0.0010\n",
      "Epoch 62/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9992\n",
      "Epoch 62: val_loss did not improve from 0.00162\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0019 - acc: 0.9992 - val_loss: 0.0118 - val_acc: 0.9960 - lr: 0.0010\n",
      "Epoch 63/500\n",
      "233/235 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9991\n",
      "Epoch 63: val_loss did not improve from 0.00162\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 0.0097 - val_acc: 0.9950 - lr: 0.0010\n",
      "Epoch 64/500\n",
      "234/235 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9967\n",
      "Epoch 64: val_loss did not improve from 0.00162\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0122 - acc: 0.9967 - val_loss: 0.0099 - val_acc: 0.9969 - lr: 0.0010\n",
      "Epoch 65/500\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.0025 - acc: 0.9995\n",
      "Epoch 65: val_loss did not improve from 0.00162\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0034 - val_acc: 0.9991 - lr: 0.0010\n",
      "Epoch 66/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9984\n",
      "Epoch 66: val_loss did not improve from 0.00162\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0058 - acc: 0.9984 - val_loss: 0.0088 - val_acc: 0.9969 - lr: 0.0010\n",
      "Epoch 67/500\n",
      "233/235 [============================>.] - ETA: 0s - loss: 5.3524e-04 - acc: 0.9999\n",
      "Epoch 67: val_loss improved from 0.00162 to 0.00154, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.3515e-04 - acc: 0.9999 - val_loss: 0.0015 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 68/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 2.9805e-04 - acc: 1.0000\n",
      "Epoch 68: val_loss improved from 0.00154 to 0.00084, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.0753e-04 - acc: 1.0000 - val_loss: 8.3504e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 69/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 0.0089 - acc: 0.9978\n",
      "Epoch 69: val_loss did not improve from 0.00084\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0086 - acc: 0.9979 - val_loss: 0.0519 - val_acc: 0.9801 - lr: 0.0010\n",
      "Epoch 70/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9984\n",
      "Epoch 70: val_loss did not improve from 0.00084\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0040 - acc: 0.9984 - val_loss: 0.0106 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 71/500\n",
      "233/235 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9997\n",
      "Epoch 71: val_loss did not improve from 0.00084\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9994 - lr: 0.0010\n",
      "Epoch 72/500\n",
      "224/235 [===========================>..] - ETA: 0s - loss: 2.5615e-04 - acc: 1.0000\n",
      "Epoch 72: val_loss did not improve from 0.00084\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.5042e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9994 - lr: 0.0010\n",
      "Epoch 73/500\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.0044 - acc: 0.9991\n",
      "Epoch 73: val_loss did not improve from 0.00084\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.0422 - val_acc: 0.9875 - lr: 0.0010\n",
      "Epoch 74/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9989\n",
      "Epoch 74: val_loss did not improve from 0.00084\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.0268 - val_acc: 0.9903 - lr: 0.0010\n",
      "Epoch 75/500\n",
      "224/235 [===========================>..] - ETA: 0s - loss: 0.0143 - acc: 0.9961\n",
      "Epoch 75: val_loss did not improve from 0.00084\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0141 - acc: 0.9961 - val_loss: 0.0188 - val_acc: 0.9963 - lr: 0.0010\n",
      "Epoch 76/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9989\n",
      "Epoch 76: val_loss did not improve from 0.00084\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0024 - acc: 0.9989 - val_loss: 0.0153 - val_acc: 0.9966 - lr: 0.0010\n",
      "Epoch 77/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9997\n",
      "Epoch 77: val_loss did not improve from 0.00084\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0055 - val_acc: 0.9994 - lr: 0.0010\n",
      "Epoch 78/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 5.7916e-04 - acc: 0.9999\n",
      "Epoch 78: val_loss did not improve from 0.00084\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 9.8597e-04 - acc: 0.9997 - val_loss: 0.0042 - val_acc: 0.9994 - lr: 0.0010\n",
      "Epoch 79/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9992\n",
      "Epoch 79: val_loss did not improve from 0.00084\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0094 - val_acc: 0.9960 - lr: 0.0010\n",
      "Epoch 80/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 5.0727e-04 - acc: 0.9999\n",
      "Epoch 80: val_loss did not improve from 0.00084\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 4.9678e-04 - acc: 0.9999 - val_loss: 0.0145 - val_acc: 0.9972 - lr: 0.0010\n",
      "Epoch 81/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9948\n",
      "Epoch 81: val_loss did not improve from 0.00084\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0182 - acc: 0.9948 - val_loss: 0.0034 - val_acc: 0.9984 - lr: 0.0010\n",
      "Epoch 82/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9996\n",
      "Epoch 82: val_loss did not improve from 0.00084\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0011 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 83/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 1.0329e-04 - acc: 1.0000\n",
      "Epoch 83: val_loss improved from 0.00084 to 0.00041, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.0321e-04 - acc: 1.0000 - val_loss: 4.0948e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 84/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9997\n",
      "Epoch 84: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0034 - acc: 0.9997 - val_loss: 0.0032 - val_acc: 0.9991 - lr: 0.0010\n",
      "Epoch 85/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 0.0101 - acc: 0.9967\n",
      "Epoch 85: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0098 - acc: 0.9968 - val_loss: 0.0190 - val_acc: 0.9928 - lr: 0.0010\n",
      "Epoch 86/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9988\n",
      "Epoch 86: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0054 - acc: 0.9988 - val_loss: 0.0101 - val_acc: 0.9981 - lr: 0.0010\n",
      "Epoch 87/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9987\n",
      "Epoch 87: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0031 - acc: 0.9987 - val_loss: 0.0141 - val_acc: 0.9947 - lr: 0.0010\n",
      "Epoch 88/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9992\n",
      "Epoch 88: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 0.0362 - val_acc: 0.9931 - lr: 0.0010\n",
      "Epoch 89/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9987\n",
      "Epoch 89: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0105 - val_acc: 0.9969 - lr: 0.0010\n",
      "Epoch 90/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9996  \n",
      "Epoch 90: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0036 - val_acc: 0.9997 - lr: 0.0010\n",
      "Epoch 91/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 3.0547e-04 - acc: 1.0000\n",
      "Epoch 91: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.9893e-04 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9994 - lr: 0.0010\n",
      "Epoch 92/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9965\n",
      "Epoch 92: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0116 - acc: 0.9965 - val_loss: 0.0101 - val_acc: 0.9960 - lr: 0.0010\n",
      "Epoch 93/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9995\n",
      "Epoch 93: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.0392 - val_acc: 0.9882 - lr: 0.0010\n",
      "Epoch 94/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9995\n",
      "Epoch 94: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0013 - acc: 0.9995 - val_loss: 0.0048 - val_acc: 0.9984 - lr: 0.0010\n",
      "Epoch 95/500\n",
      "233/235 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9991\n",
      "Epoch 95: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0052 - acc: 0.9991 - val_loss: 0.0408 - val_acc: 0.9900 - lr: 0.0010\n",
      "Epoch 96/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9969\n",
      "Epoch 96: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0102 - acc: 0.9968 - val_loss: 0.0013 - val_acc: 0.9997 - lr: 0.0010\n",
      "Epoch 97/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 0.0078 - acc: 0.9981\n",
      "Epoch 97: val_loss did not improve from 0.00041\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0075 - acc: 0.9981 - val_loss: 0.0202 - val_acc: 0.9966 - lr: 0.0010\n",
      "Epoch 98/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9995\n",
      "Epoch 98: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.0168 - val_acc: 0.9975 - lr: 5.0000e-04\n",
      "Epoch 99/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 2.5392e-04 - acc: 0.9999\n",
      "Epoch 99: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.5052e-04 - acc: 0.9999 - val_loss: 0.0071 - val_acc: 0.9984 - lr: 5.0000e-04\n",
      "Epoch 100/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 2.3372e-04 - acc: 1.0000\n",
      "Epoch 100: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.2912e-04 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 0.9975 - lr: 5.0000e-04\n",
      "Epoch 101/500\n",
      "225/235 [===========================>..] - ETA: 0s - loss: 8.5895e-05 - acc: 1.0000\n",
      "Epoch 101: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 8.4016e-05 - acc: 1.0000 - val_loss: 0.0180 - val_acc: 0.9975 - lr: 5.0000e-04\n",
      "Epoch 102/500\n",
      "225/235 [===========================>..] - ETA: 0s - loss: 1.2331e-04 - acc: 1.0000\n",
      "Epoch 102: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.2268e-04 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 0.9972 - lr: 5.0000e-04\n",
      "Epoch 103/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 4.0968e-04 - acc: 0.9999\n",
      "Epoch 103: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.9651e-04 - acc: 0.9999 - val_loss: 0.0230 - val_acc: 0.9972 - lr: 5.0000e-04\n",
      "Epoch 104/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 7.9626e-04 - acc: 0.9995\n",
      "Epoch 104: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 7.8884e-04 - acc: 0.9995 - val_loss: 0.0022 - val_acc: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 105/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 105: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 0.0044 - val_acc: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 106/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9989\n",
      "Epoch 106: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0041 - acc: 0.9989 - val_loss: 0.0086 - val_acc: 0.9975 - lr: 5.0000e-04\n",
      "Epoch 107/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 4.4288e-04 - acc: 0.9999\n",
      "Epoch 107: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 4.3540e-04 - acc: 0.9999 - val_loss: 0.0166 - val_acc: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 108/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 0.0030 - acc: 0.9992\n",
      "Epoch 108: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0029 - acc: 0.9992 - val_loss: 0.0123 - val_acc: 0.9975 - lr: 5.0000e-04\n",
      "Epoch 109/500\n",
      "233/235 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9997\n",
      "Epoch 109: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0024 - acc: 0.9997 - val_loss: 0.0070 - val_acc: 0.9975 - lr: 5.0000e-04\n",
      "Epoch 110/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 4.2707e-04 - acc: 0.9999\n",
      "Epoch 110: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 4.2520e-04 - acc: 0.9999 - val_loss: 0.0106 - val_acc: 0.9972 - lr: 5.0000e-04\n",
      "Epoch 111/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 1.6510e-04 - acc: 1.0000\n",
      "Epoch 111: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.6139e-04 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 0.9988 - lr: 5.0000e-04\n",
      "Epoch 112/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 3.8202e-05 - acc: 1.0000\n",
      "Epoch 112: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.7334e-05 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 0.9988 - lr: 5.0000e-04\n",
      "Epoch 113/500\n",
      "233/235 [============================>.] - ETA: 0s - loss: 2.0604e-04 - acc: 1.0000\n",
      "Epoch 113: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.0509e-04 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 0.9988 - lr: 5.0000e-04\n",
      "Epoch 114/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9996    \n",
      "Epoch 114: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0117 - val_acc: 0.9975 - lr: 5.0000e-04\n",
      "Epoch 115/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 1.2842e-04 - acc: 1.0000\n",
      "Epoch 115: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.2535e-04 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 116/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 2.4241e-05 - acc: 1.0000\n",
      "Epoch 116: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.3951e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 117/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 2.5843e-05 - acc: 1.0000\n",
      "Epoch 117: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.5184e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 118/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 1.8061e-04 - acc: 0.9999\n",
      "Epoch 118: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.7727e-04 - acc: 0.9999 - val_loss: 0.0032 - val_acc: 0.9991 - lr: 5.0000e-04\n",
      "Epoch 119/500\n",
      "225/235 [===========================>..] - ETA: 0s - loss: 4.1273e-04 - acc: 0.9999\n",
      "Epoch 119: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.9691e-04 - acc: 0.9999 - val_loss: 0.0051 - val_acc: 0.9988 - lr: 5.0000e-04\n",
      "Epoch 120/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 8.1132e-05 - acc: 1.0000\n",
      "Epoch 120: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 7.9913e-05 - acc: 1.0000 - val_loss: 0.0256 - val_acc: 0.9944 - lr: 5.0000e-04\n",
      "Epoch 121/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9984\n",
      "Epoch 121: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0058 - acc: 0.9984 - val_loss: 0.0228 - val_acc: 0.9913 - lr: 5.0000e-04\n",
      "Epoch 122/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9995\n",
      "Epoch 122: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0032 - acc: 0.9995 - val_loss: 0.0046 - val_acc: 0.9978 - lr: 5.0000e-04\n",
      "Epoch 123/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 2.0126e-04 - acc: 1.0000\n",
      "Epoch 123: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.9998e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 124/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 6.9351e-05 - acc: 1.0000\n",
      "Epoch 124: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 6.8396e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 125/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 6.2027e-05 - acc: 1.0000\n",
      "Epoch 125: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.2090e-04 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 126/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 1.2913e-04 - acc: 1.0000\n",
      "Epoch 126: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.2528e-04 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 0.9978 - lr: 5.0000e-04\n",
      "Epoch 127/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 5.9637e-04 - acc: 0.9999\n",
      "Epoch 127: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.8344e-04 - acc: 0.9999 - val_loss: 0.0030 - val_acc: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 128/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 9.9047e-05 - acc: 1.0000\n",
      "Epoch 128: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 9.8165e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9997 - lr: 5.0000e-04\n",
      "Epoch 129/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 8.6217e-05 - acc: 1.0000\n",
      "Epoch 129: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 8.5727e-05 - acc: 1.0000 - val_loss: 5.7781e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 130/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 2.6000e-04 - acc: 0.9999\n",
      "Epoch 130: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.5226e-04 - acc: 0.9999 - val_loss: 0.0020 - val_acc: 0.9991 - lr: 5.0000e-04\n",
      "Epoch 131/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 3.1229e-05 - acc: 1.0000\n",
      "Epoch 131: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.0794e-05 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9978 - lr: 5.0000e-04\n",
      "Epoch 132/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9996\n",
      "Epoch 132: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0262 - val_acc: 0.9928 - lr: 5.0000e-04\n",
      "Epoch 133/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 0.0043 - acc: 0.9992 \n",
      "Epoch 133: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0041 - acc: 0.9992 - val_loss: 0.0349 - val_acc: 0.9931 - lr: 5.0000e-04\n",
      "Epoch 134/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 5.5919e-04 - acc: 0.9997\n",
      "Epoch 134: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.4488e-04 - acc: 0.9997 - val_loss: 0.0119 - val_acc: 0.9975 - lr: 5.0000e-04\n",
      "Epoch 135/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 2.9400e-05 - acc: 1.0000\n",
      "Epoch 135: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.9057e-05 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9975 - lr: 5.0000e-04\n",
      "Epoch 136/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 1.5097e-04 - acc: 1.0000\n",
      "Epoch 136: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.4926e-04 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 0.9975 - lr: 5.0000e-04\n",
      "Epoch 137/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 2.6650e-04 - acc: 0.9999\n",
      "Epoch 137: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.5952e-04 - acc: 0.9999 - val_loss: 0.0093 - val_acc: 0.9972 - lr: 5.0000e-04\n",
      "Epoch 138/500\n",
      "225/235 [===========================>..] - ETA: 0s - loss: 3.3142e-05 - acc: 1.0000\n",
      "Epoch 138: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.2863e-05 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9978 - lr: 5.0000e-04\n",
      "Epoch 139/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 2.1836e-05 - acc: 1.0000\n",
      "Epoch 139: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.1608e-05 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 140/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 8.7951e-05 - acc: 1.0000\n",
      "Epoch 140: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 8.6185e-05 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 0.9953 - lr: 5.0000e-04\n",
      "Epoch 141/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 0.0051 - acc: 0.9988\n",
      "Epoch 141: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0049 - acc: 0.9988 - val_loss: 0.0148 - val_acc: 0.9941 - lr: 5.0000e-04\n",
      "Epoch 142/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 0.0047 - acc: 0.9990\n",
      "Epoch 142: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0045 - acc: 0.9991 - val_loss: 0.0209 - val_acc: 0.9960 - lr: 5.0000e-04\n",
      "Epoch 143/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 5.4080e-04 - acc: 0.9997\n",
      "Epoch 143: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.3545e-04 - acc: 0.9997 - val_loss: 0.0167 - val_acc: 0.9972 - lr: 5.0000e-04\n",
      "Epoch 144/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 1.0609e-04 - acc: 1.0000\n",
      "Epoch 144: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.0508e-04 - acc: 1.0000 - val_loss: 0.0267 - val_acc: 0.9953 - lr: 5.0000e-04\n",
      "Epoch 145/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 7.3262e-05 - acc: 1.0000\n",
      "Epoch 145: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 7.2662e-05 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 0.9956 - lr: 5.0000e-04\n",
      "Epoch 146/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 3.5398e-05 - acc: 1.0000\n",
      "Epoch 146: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.4336e-05 - acc: 1.0000 - val_loss: 0.0284 - val_acc: 0.9956 - lr: 5.0000e-04\n",
      "Epoch 147/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9995\n",
      "Epoch 147: val_loss did not improve from 0.00041\n",
      "\n",
      "Epoch 147: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.0198 - val_acc: 0.9972 - lr: 5.0000e-04\n",
      "Epoch 148/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 7.4285e-05 - acc: 1.0000\n",
      "Epoch 148: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 7.2215e-05 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 0.9966 - lr: 2.5000e-04\n",
      "Epoch 149/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 1.1882e-04 - acc: 0.9999\n",
      "Epoch 149: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.1557e-04 - acc: 0.9999 - val_loss: 0.0255 - val_acc: 0.9956 - lr: 2.5000e-04\n",
      "Epoch 150/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 8.4625e-05 - acc: 1.0000\n",
      "Epoch 150: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 8.3008e-05 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 0.9960 - lr: 2.5000e-04\n",
      "Epoch 151/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 2.6530e-04 - acc: 0.9999\n",
      "Epoch 151: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.6113e-04 - acc: 0.9999 - val_loss: 0.0276 - val_acc: 0.9956 - lr: 2.5000e-04\n",
      "Epoch 152/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 3.5103e-04 - acc: 0.9997\n",
      "Epoch 152: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.4944e-04 - acc: 0.9997 - val_loss: 0.0402 - val_acc: 0.9950 - lr: 2.5000e-04\n",
      "Epoch 153/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 5.6645e-04 - acc: 0.9997\n",
      "Epoch 153: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.4986e-04 - acc: 0.9997 - val_loss: 0.0035 - val_acc: 0.9984 - lr: 2.5000e-04\n",
      "Epoch 154/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9997\n",
      "Epoch 154: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0028 - val_acc: 0.9988 - lr: 2.5000e-04\n",
      "Epoch 155/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 9.8693e-05 - acc: 1.0000\n",
      "Epoch 155: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 9.5464e-05 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 0.9994 - lr: 2.5000e-04\n",
      "Epoch 156/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 1.8491e-05 - acc: 1.0000\n",
      "Epoch 156: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.8353e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9994 - lr: 2.5000e-04\n",
      "Epoch 157/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 7.9899e-04 - acc: 0.9997\n",
      "Epoch 157: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 7.8523e-04 - acc: 0.9997 - val_loss: 6.6960e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 158/500\n",
      "233/235 [============================>.] - ETA: 0s - loss: 4.5174e-05 - acc: 1.0000\n",
      "Epoch 158: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 4.5319e-05 - acc: 1.0000 - val_loss: 8.6818e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 159/500\n",
      "225/235 [===========================>..] - ETA: 0s - loss: 1.9926e-05 - acc: 1.0000\n",
      "Epoch 159: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.9247e-05 - acc: 1.0000 - val_loss: 8.9954e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 160/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 5.7010e-06 - acc: 1.0000\n",
      "Epoch 160: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.6157e-06 - acc: 1.0000 - val_loss: 8.9431e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 161/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 5.0117e-06 - acc: 1.0000\n",
      "Epoch 161: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 4.9571e-06 - acc: 1.0000 - val_loss: 8.7866e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 162/500\n",
      "225/235 [===========================>..] - ETA: 0s - loss: 2.5212e-05 - acc: 1.0000\n",
      "Epoch 162: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.4335e-05 - acc: 1.0000 - val_loss: 7.2533e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 163/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 2.1970e-05 - acc: 1.0000\n",
      "Epoch 163: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.1460e-05 - acc: 1.0000 - val_loss: 7.1396e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 164/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 6.6585e-06 - acc: 1.0000\n",
      "Epoch 164: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 6.5218e-06 - acc: 1.0000 - val_loss: 6.3348e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 165/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 1.3543e-05 - acc: 1.0000\n",
      "Epoch 165: val_loss did not improve from 0.00041\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.3455e-05 - acc: 1.0000 - val_loss: 6.2194e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 166/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 6.4570e-05 - acc: 1.0000\n",
      "Epoch 166: val_loss improved from 0.00041 to 0.00032, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 6.3776e-05 - acc: 1.0000 - val_loss: 3.2368e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 167/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 0.0013 - acc: 0.9999\n",
      "Epoch 167: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0012 - acc: 0.9999 - val_loss: 0.0389 - val_acc: 0.9944 - lr: 2.5000e-04\n",
      "Epoch 168/500\n",
      "225/235 [===========================>..] - ETA: 0s - loss: 2.0018e-05 - acc: 1.0000\n",
      "Epoch 168: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.1935e-05 - acc: 1.0000 - val_loss: 0.0394 - val_acc: 0.9944 - lr: 2.5000e-04\n",
      "Epoch 169/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 2.0249e-04 - acc: 1.0000\n",
      "Epoch 169: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.9969e-04 - acc: 1.0000 - val_loss: 0.0445 - val_acc: 0.9944 - lr: 2.5000e-04\n",
      "Epoch 170/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 2.4528e-04 - acc: 0.9999\n",
      "Epoch 170: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.4207e-04 - acc: 0.9999 - val_loss: 0.0011 - val_acc: 0.9997 - lr: 2.5000e-04\n",
      "Epoch 171/500\n",
      "225/235 [===========================>..] - ETA: 0s - loss: 5.3967e-05 - acc: 1.0000\n",
      "Epoch 171: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.2143e-05 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 172/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 1.5491e-05 - acc: 1.0000\n",
      "Epoch 172: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.5236e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 173/500\n",
      "233/235 [============================>.] - ETA: 0s - loss: 1.6436e-05 - acc: 1.0000\n",
      "Epoch 173: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.6361e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 174/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 1.7256e-05 - acc: 1.0000\n",
      "Epoch 174: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.6821e-05 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 175/500\n",
      "234/235 [============================>.] - ETA: 0s - loss: 2.8511e-04 - acc: 0.9999\n",
      "Epoch 175: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8499e-04 - acc: 0.9999 - val_loss: 0.0025 - val_acc: 0.9991 - lr: 2.5000e-04\n",
      "Epoch 176/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 7.5195e-05 - acc: 1.0000\n",
      "Epoch 176: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 7.3321e-05 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 0.9981 - lr: 2.5000e-04\n",
      "Epoch 177/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 8.3282e-06 - acc: 1.0000\n",
      "Epoch 177: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 8.1742e-06 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 0.9991 - lr: 2.5000e-04\n",
      "Epoch 178/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 1.4035e-04 - acc: 0.9999\n",
      "Epoch 178: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.3770e-04 - acc: 0.9999 - val_loss: 4.4086e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 179/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 6.2012e-05 - acc: 1.0000\n",
      "Epoch 179: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 6.0722e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9991 - lr: 2.5000e-04\n",
      "Epoch 180/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 2.3008e-05 - acc: 1.0000\n",
      "Epoch 180: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.3285e-05 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9994 - lr: 2.5000e-04\n",
      "Epoch 181/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 6.2501e-06 - acc: 1.0000\n",
      "Epoch 181: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 6.2002e-06 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9991 - lr: 2.5000e-04\n",
      "Epoch 182/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 3.2680e-06 - acc: 1.0000\n",
      "Epoch 182: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.4121e-06 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 0.9991 - lr: 2.5000e-04\n",
      "Epoch 183/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 3.0962e-04 - acc: 0.9999\n",
      "Epoch 183: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.0339e-04 - acc: 0.9999 - val_loss: 0.0110 - val_acc: 0.9963 - lr: 2.5000e-04\n",
      "Epoch 184/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 2.2150e-05 - acc: 1.0000\n",
      "Epoch 184: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.1804e-05 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 0.9966 - lr: 2.5000e-04\n",
      "Epoch 185/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 8.9800e-06 - acc: 1.0000\n",
      "Epoch 185: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 8.8565e-06 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 0.9972 - lr: 2.5000e-04\n",
      "Epoch 186/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9991\n",
      "Epoch 186: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0101 - acc: 0.9991 - val_loss: 0.0132 - val_acc: 0.9956 - lr: 2.5000e-04\n",
      "Epoch 187/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 3.6443e-04 - acc: 1.0000\n",
      "Epoch 187: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.5427e-04 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 0.9953 - lr: 2.5000e-04\n",
      "Epoch 188/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 5.3604e-05 - acc: 1.0000\n",
      "Epoch 188: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.2315e-05 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 0.9956 - lr: 2.5000e-04\n",
      "Epoch 189/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 3.1189e-05 - acc: 1.0000\n",
      "Epoch 189: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.0894e-05 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 0.9972 - lr: 2.5000e-04\n",
      "Epoch 190/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 8.5098e-05 - acc: 1.0000\n",
      "Epoch 190: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 8.2905e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9997 - lr: 2.5000e-04\n",
      "Epoch 191/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 1.3679e-05 - acc: 1.0000\n",
      "Epoch 191: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.3401e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9997 - lr: 2.5000e-04\n",
      "Epoch 192/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 9.6416e-05 - acc: 1.0000\n",
      "Epoch 192: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.0216e-04 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 0.9963 - lr: 2.5000e-04\n",
      "Epoch 193/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 2.1713e-05 - acc: 1.0000\n",
      "Epoch 193: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.1262e-05 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9969 - lr: 2.5000e-04\n",
      "Epoch 194/500\n",
      "224/235 [===========================>..] - ETA: 0s - loss: 1.6172e-05 - acc: 1.0000\n",
      "Epoch 194: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.5920e-05 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9975 - lr: 2.5000e-04\n",
      "Epoch 195/500\n",
      "225/235 [===========================>..] - ETA: 0s - loss: 6.8363e-05 - acc: 1.0000\n",
      "Epoch 195: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 6.5768e-05 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9969 - lr: 2.5000e-04\n",
      "Epoch 196/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 2.2513e-04 - acc: 0.9999\n",
      "Epoch 196: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.2222e-04 - acc: 0.9999 - val_loss: 4.5336e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 197/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 1.2585e-05 - acc: 1.0000\n",
      "Epoch 197: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 197: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.2432e-05 - acc: 1.0000 - val_loss: 5.4063e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 198/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 1.2663e-05 - acc: 1.0000\n",
      "Epoch 198: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 2.7272e-05 - acc: 1.0000 - val_loss: 4.8674e-04 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 199/500\n",
      "235/235 [==============================] - ETA: 0s - loss: 9.0181e-06 - acc: 1.0000\n",
      "Epoch 199: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 9.0181e-06 - acc: 1.0000 - val_loss: 4.5192e-04 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 200/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 4.0945e-05 - acc: 1.0000\n",
      "Epoch 200: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 4.3991e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9997 - lr: 1.2500e-04\n",
      "Epoch 201/500\n",
      "233/235 [============================>.] - ETA: 0s - loss: 1.5070e-05 - acc: 1.0000\n",
      "Epoch 201: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.5000e-05 - acc: 1.0000 - val_loss: 9.0936e-04 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 202/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 3.0005e-05 - acc: 1.0000\n",
      "Epoch 202: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.9174e-05 - acc: 1.0000 - val_loss: 9.7311e-04 - val_acc: 0.9997 - lr: 1.2500e-04\n",
      "Epoch 203/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 8.9682e-06 - acc: 1.0000\n",
      "Epoch 203: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 8.8312e-06 - acc: 1.0000 - val_loss: 9.1548e-04 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 204/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 3.7850e-05 - acc: 1.0000\n",
      "Epoch 204: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.6792e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9997 - lr: 1.2500e-04\n",
      "Epoch 205/500\n",
      "225/235 [===========================>..] - ETA: 0s - loss: 1.0607e-05 - acc: 1.0000\n",
      "Epoch 205: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.0237e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9997 - lr: 1.2500e-04\n",
      "Epoch 206/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 4.8336e-06 - acc: 1.0000\n",
      "Epoch 206: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 8.5513e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9997 - lr: 1.2500e-04\n",
      "Epoch 207/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 5.6141e-05 - acc: 1.0000\n",
      "Epoch 207: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.7736e-05 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 0.9984 - lr: 1.2500e-04\n",
      "Epoch 208/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 1.4723e-05 - acc: 1.0000\n",
      "Epoch 208: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.4378e-05 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 0.9984 - lr: 1.2500e-04\n",
      "Epoch 209/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 7.2711e-05 - acc: 1.0000\n",
      "Epoch 209: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 7.4854e-05 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 0.9978 - lr: 1.2500e-04\n",
      "Epoch 210/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 6.7614e-06 - acc: 1.0000\n",
      "Epoch 210: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 6.6998e-06 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9997 - lr: 1.2500e-04\n",
      "Epoch 211/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 3.1476e-05 - acc: 1.0000\n",
      "Epoch 211: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.0801e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 0.9997 - lr: 1.2500e-04\n",
      "Epoch 212/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 5.4165e-06 - acc: 1.0000\n",
      "Epoch 212: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.3715e-06 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9997 - lr: 1.2500e-04\n",
      "Epoch 213/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 2.7448e-06 - acc: 1.0000\n",
      "Epoch 213: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.6920e-06 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 0.9997 - lr: 1.2500e-04\n",
      "Epoch 214/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 2.2485e-06 - acc: 1.0000\n",
      "Epoch 214: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.2142e-06 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9997 - lr: 1.2500e-04\n",
      "Epoch 215/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 2.8447e-06 - acc: 1.0000\n",
      "Epoch 215: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.7681e-06 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9997 - lr: 1.2500e-04\n",
      "Epoch 216/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 5.0576e-06 - acc: 1.0000\n",
      "Epoch 216: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 4.9321e-06 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9997 - lr: 1.2500e-04\n",
      "Epoch 217/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 1.6778e-06 - acc: 1.0000\n",
      "Epoch 217: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.6347e-06 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 0.9997 - lr: 1.2500e-04\n",
      "Epoch 218/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 1.8978e-06 - acc: 1.0000\n",
      "Epoch 218: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.8606e-06 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 0.9997 - lr: 1.2500e-04\n",
      "Epoch 219/500\n",
      "225/235 [===========================>..] - ETA: 0s - loss: 1.3059e-05 - acc: 1.0000\n",
      "Epoch 219: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.2977e-05 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9994 - lr: 1.2500e-04\n",
      "Epoch 220/500\n",
      "225/235 [===========================>..] - ETA: 0s - loss: 2.3858e-06 - acc: 1.0000\n",
      "Epoch 220: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.3188e-06 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 0.9997 - lr: 1.2500e-04\n",
      "Epoch 221/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 1.4179e-06 - acc: 1.0000\n",
      "Epoch 221: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.3968e-06 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9997 - lr: 1.2500e-04\n",
      "Epoch 222/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 4.0395e-05 - acc: 1.0000\n",
      "Epoch 222: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.9183e-05 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9966 - lr: 1.2500e-04\n",
      "Epoch 223/500\n",
      "225/235 [===========================>..] - ETA: 0s - loss: 2.4653e-05 - acc: 1.0000\n",
      "Epoch 223: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.3704e-05 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 0.9975 - lr: 1.2500e-04\n",
      "Epoch 224/500\n",
      "224/235 [===========================>..] - ETA: 0s - loss: 1.1770e-06 - acc: 1.0000\n",
      "Epoch 224: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 1.2416e-06 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 0.9978 - lr: 1.2500e-04\n",
      "Epoch 225/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 9.9261e-07 - acc: 1.0000\n",
      "Epoch 225: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.0059e-06 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 0.9978 - lr: 1.2500e-04\n",
      "Epoch 226/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 1.1027e-06 - acc: 1.0000\n",
      "Epoch 226: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.0697e-06 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 0.9978 - lr: 1.2500e-04\n",
      "Epoch 227/500\n",
      "235/235 [==============================] - ETA: 0s - loss: 1.1163e-06 - acc: 1.0000\n",
      "Epoch 227: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.1163e-06 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 0.9978 - lr: 1.2500e-04\n",
      "Epoch 228/500\n",
      "234/235 [============================>.] - ETA: 0s - loss: 1.1612e-06 - acc: 1.0000\n",
      "Epoch 228: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.1608e-06 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9978 - lr: 1.2500e-04\n",
      "Epoch 229/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 3.6663e-06 - acc: 1.0000\n",
      "Epoch 229: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.5851e-06 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 0.9975 - lr: 1.2500e-04\n",
      "Epoch 230/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 1.3883e-06 - acc: 1.0000\n",
      "Epoch 230: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.3485e-06 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9975 - lr: 1.2500e-04\n",
      "Epoch 231/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 1.8518e-05 - acc: 1.0000\n",
      "Epoch 231: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.8275e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 0.9994 - lr: 1.2500e-04\n",
      "Epoch 232/500\n",
      "225/235 [===========================>..] - ETA: 0s - loss: 6.1637e-06 - acc: 1.0000\n",
      "Epoch 232: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.9356e-06 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 0.9997 - lr: 1.2500e-04\n",
      "Epoch 233/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 1.0739e-06 - acc: 1.0000\n",
      "Epoch 233: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.0660e-06 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 0.9994 - lr: 1.2500e-04\n",
      "Epoch 234/500\n",
      "234/235 [============================>.] - ETA: 0s - loss: 1.3269e-05 - acc: 1.0000\n",
      "Epoch 234: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.3264e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9991 - lr: 1.2500e-04\n",
      "Epoch 235/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 1.9161e-04 - acc: 0.9999\n",
      "Epoch 235: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.8669e-04 - acc: 0.9999 - val_loss: 0.0158 - val_acc: 0.9966 - lr: 1.2500e-04\n",
      "Epoch 236/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 4.2602e-06 - acc: 1.0000\n",
      "Epoch 236: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 4.3154e-06 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 0.9966 - lr: 1.2500e-04\n",
      "Epoch 237/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 3.1855e-06 - acc: 1.0000\n",
      "Epoch 237: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.0973e-06 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 0.9975 - lr: 1.2500e-04\n",
      "Epoch 238/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 0.0017 - acc: 0.9997\n",
      "Epoch 238: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0054 - val_acc: 0.9984 - lr: 1.2500e-04\n",
      "Epoch 239/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 3.2080e-06 - acc: 1.0000\n",
      "Epoch 239: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.1682e-06 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 0.9981 - lr: 1.2500e-04\n",
      "Epoch 240/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 2.1981e-05 - acc: 1.0000\n",
      "Epoch 240: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.1511e-05 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9975 - lr: 1.2500e-04\n",
      "Epoch 241/500\n",
      "225/235 [===========================>..] - ETA: 0s - loss: 7.8118e-06 - acc: 1.0000\n",
      "Epoch 241: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 7.5912e-06 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 0.9981 - lr: 1.2500e-04\n",
      "Epoch 242/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 2.3128e-06 - acc: 1.0000\n",
      "Epoch 242: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.2526e-06 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 0.9984 - lr: 1.2500e-04\n",
      "Epoch 243/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 2.7391e-06 - acc: 1.0000\n",
      "Epoch 243: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.7076e-06 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 0.9981 - lr: 1.2500e-04\n",
      "Epoch 244/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 2.7183e-05 - acc: 1.0000\n",
      "Epoch 244: val_loss did not improve from 0.00032\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.6940e-05 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 0.9975 - lr: 1.2500e-04\n",
      "Epoch 245/500\n",
      "233/235 [============================>.] - ETA: 0s - loss: 3.5836e-06 - acc: 1.0000\n",
      "Epoch 245: val_loss improved from 0.00032 to 0.00023, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.5669e-06 - acc: 1.0000 - val_loss: 2.2765e-04 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 246/500\n",
      "224/235 [===========================>..] - ETA: 0s - loss: 2.1888e-06 - acc: 1.0000\n",
      "Epoch 246: val_loss improved from 0.00023 to 0.00020, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.1044e-06 - acc: 1.0000 - val_loss: 1.9991e-04 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 247/500\n",
      "234/235 [============================>.] - ETA: 0s - loss: 1.1056e-05 - acc: 1.0000\n",
      "Epoch 247: val_loss improved from 0.00020 to 0.00019, saving model to models\\model.h5\n",
      "\n",
      "Epoch 247: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.1052e-05 - acc: 1.0000 - val_loss: 1.8862e-04 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 248/500\n",
      "225/235 [===========================>..] - ETA: 0s - loss: 7.9587e-04 - acc: 0.9999\n",
      "Epoch 248: val_loss improved from 0.00019 to 0.00014, saving model to models\\model.h5\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 7.6498e-04 - acc: 0.9999 - val_loss: 1.4231e-04 - val_acc: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 249/500\n",
      "224/235 [===========================>..] - ETA: 0s - loss: 2.5648e-06 - acc: 1.0000\n",
      "Epoch 249: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.5684e-06 - acc: 1.0000 - val_loss: 1.4451e-04 - val_acc: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 250/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 9.0722e-07 - acc: 1.0000\n",
      "Epoch 250: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 9.0288e-07 - acc: 1.0000 - val_loss: 1.4836e-04 - val_acc: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 251/500\n",
      "233/235 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9999\n",
      "Epoch 251: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0025 - acc: 0.9999 - val_loss: 4.4094e-04 - val_acc: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 252/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 2.2457e-06 - acc: 1.0000\n",
      "Epoch 252: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.2267e-06 - acc: 1.0000 - val_loss: 4.5567e-04 - val_acc: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 253/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 1.2355e-06 - acc: 1.0000\n",
      "Epoch 253: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.2108e-06 - acc: 1.0000 - val_loss: 4.8660e-04 - val_acc: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 254/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 8.2529e-06 - acc: 1.0000\n",
      "Epoch 254: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 8.1481e-06 - acc: 1.0000 - val_loss: 6.7580e-04 - val_acc: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 255/500\n",
      "233/235 [============================>.] - ETA: 0s - loss: 3.5416e-06 - acc: 1.0000\n",
      "Epoch 255: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.5251e-06 - acc: 1.0000 - val_loss: 4.4671e-04 - val_acc: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 256/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 1.2848e-06 - acc: 1.0000\n",
      "Epoch 256: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.2632e-06 - acc: 1.0000 - val_loss: 4.3193e-04 - val_acc: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 257/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 1.4198e-06 - acc: 1.0000\n",
      "Epoch 257: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.4769e-06 - acc: 1.0000 - val_loss: 5.1366e-04 - val_acc: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 258/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 2.5962e-05 - acc: 1.0000\n",
      "Epoch 258: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.5623e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 0.9997 - lr: 6.2500e-05\n",
      "Epoch 259/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 1.5598e-05 - acc: 1.0000\n",
      "Epoch 259: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.5325e-05 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9991 - lr: 6.2500e-05\n",
      "Epoch 260/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 2.5750e-07 - acc: 1.0000\n",
      "Epoch 260: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.5311e-07 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9991 - lr: 6.2500e-05\n",
      "Epoch 261/500\n",
      "233/235 [============================>.] - ETA: 0s - loss: 9.1031e-07 - acc: 1.0000\n",
      "Epoch 261: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 9.0663e-07 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9991 - lr: 6.2500e-05\n",
      "Epoch 262/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 2.6786e-07 - acc: 1.0000\n",
      "Epoch 262: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.6496e-07 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9991 - lr: 6.2500e-05\n",
      "Epoch 263/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 1.4739e-06 - acc: 1.0000\n",
      "Epoch 263: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.4423e-06 - acc: 1.0000 - val_loss: 9.8770e-04 - val_acc: 0.9997 - lr: 6.2500e-05\n",
      "Epoch 264/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 1.1817e-06 - acc: 1.0000\n",
      "Epoch 264: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.1577e-06 - acc: 1.0000 - val_loss: 9.9101e-04 - val_acc: 0.9997 - lr: 6.2500e-05\n",
      "Epoch 265/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 7.6559e-06 - acc: 1.0000\n",
      "Epoch 265: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 7.5603e-06 - acc: 1.0000 - val_loss: 3.4602e-04 - val_acc: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 266/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 6.7858e-06 - acc: 1.0000\n",
      "Epoch 266: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 6.6248e-06 - acc: 1.0000 - val_loss: 2.8759e-04 - val_acc: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 267/500\n",
      "233/235 [============================>.] - ETA: 0s - loss: 4.8627e-07 - acc: 1.0000\n",
      "Epoch 267: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 4.8415e-07 - acc: 1.0000 - val_loss: 2.8939e-04 - val_acc: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 268/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 3.0315e-06 - acc: 1.0000\n",
      "Epoch 268: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.9788e-06 - acc: 1.0000 - val_loss: 7.4955e-04 - val_acc: 0.9997 - lr: 6.2500e-05\n",
      "Epoch 269/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 3.2142e-07 - acc: 1.0000\n",
      "Epoch 269: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.1406e-07 - acc: 1.0000 - val_loss: 8.3529e-04 - val_acc: 0.9997 - lr: 6.2500e-05\n",
      "Epoch 270/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 5.1495e-07 - acc: 1.0000\n",
      "Epoch 270: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.0836e-07 - acc: 1.0000 - val_loss: 9.0995e-04 - val_acc: 0.9997 - lr: 6.2500e-05\n",
      "Epoch 271/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 9.6693e-07 - acc: 1.0000\n",
      "Epoch 271: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 9.4264e-07 - acc: 1.0000 - val_loss: 9.4261e-04 - val_acc: 0.9997 - lr: 6.2500e-05\n",
      "Epoch 272/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 3.1842e-07 - acc: 1.0000\n",
      "Epoch 272: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.1310e-07 - acc: 1.0000 - val_loss: 9.3572e-04 - val_acc: 0.9997 - lr: 6.2500e-05\n",
      "Epoch 273/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 1.3839e-07 - acc: 1.0000\n",
      "Epoch 273: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.7116e-07 - acc: 1.0000 - val_loss: 9.0677e-04 - val_acc: 0.9997 - lr: 6.2500e-05\n",
      "Epoch 274/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 3.2211e-07 - acc: 1.0000\n",
      "Epoch 274: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.1601e-07 - acc: 1.0000 - val_loss: 8.6374e-04 - val_acc: 0.9997 - lr: 6.2500e-05\n",
      "Epoch 275/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 4.9599e-06 - acc: 1.0000\n",
      "Epoch 275: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 4.8337e-06 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 0.9975 - lr: 6.2500e-05\n",
      "Epoch 276/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 4.1958e-07 - acc: 1.0000\n",
      "Epoch 276: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 4.2920e-07 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9975 - lr: 6.2500e-05\n",
      "Epoch 277/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 2.8724e-06 - acc: 1.0000\n",
      "Epoch 277: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.8469e-06 - acc: 1.0000 - val_loss: 0.0220 - val_acc: 0.9963 - lr: 6.2500e-05\n",
      "Epoch 278/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 9.0773e-07 - acc: 1.0000\n",
      "Epoch 278: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 8.9941e-07 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 0.9969 - lr: 6.2500e-05\n",
      "Epoch 279/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 1.4561e-06 - acc: 1.0000\n",
      "Epoch 279: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.4433e-06 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 0.9972 - lr: 6.2500e-05\n",
      "Epoch 280/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 2.4160e-04 - acc: 0.9999\n",
      "Epoch 280: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.3326e-04 - acc: 0.9999 - val_loss: 5.6511e-04 - val_acc: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 281/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 1.2833e-06 - acc: 1.0000\n",
      "Epoch 281: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.2530e-06 - acc: 1.0000 - val_loss: 6.6097e-04 - val_acc: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 282/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 1.0085e-06 - acc: 1.0000\n",
      "Epoch 282: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 9.9517e-07 - acc: 1.0000 - val_loss: 8.6834e-04 - val_acc: 0.9997 - lr: 6.2500e-05\n",
      "Epoch 283/500\n",
      "233/235 [============================>.] - ETA: 0s - loss: 1.8927e-05 - acc: 1.0000\n",
      "Epoch 283: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.8840e-05 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9972 - lr: 6.2500e-05\n",
      "Epoch 284/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 1.2019e-06 - acc: 1.0000\n",
      "Epoch 284: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.2127e-06 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 0.9972 - lr: 6.2500e-05\n",
      "Epoch 285/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 4.3079e-05 - acc: 1.0000\n",
      "Epoch 285: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 4.2332e-05 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 0.9975 - lr: 6.2500e-05\n",
      "Epoch 286/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 8.3897e-06 - acc: 1.0000\n",
      "Epoch 286: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 8.2458e-06 - acc: 1.0000 - val_loss: 0.0166 - val_acc: 0.9969 - lr: 6.2500e-05\n",
      "Epoch 287/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 6.3664e-07 - acc: 1.0000\n",
      "Epoch 287: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 6.3017e-07 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 0.9969 - lr: 6.2500e-05\n",
      "Epoch 288/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 8.8732e-07 - acc: 1.0000\n",
      "Epoch 288: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 8.7008e-07 - acc: 1.0000 - val_loss: 0.0154 - val_acc: 0.9969 - lr: 6.2500e-05\n",
      "Epoch 289/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 3.2653e-06 - acc: 1.0000\n",
      "Epoch 289: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.1698e-06 - acc: 1.0000 - val_loss: 0.0146 - val_acc: 0.9969 - lr: 6.2500e-05\n",
      "Epoch 290/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 2.3437e-07 - acc: 1.0000\n",
      "Epoch 290: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.3698e-07 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 0.9969 - lr: 6.2500e-05\n",
      "Epoch 291/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 3.6195e-07 - acc: 1.0000\n",
      "Epoch 291: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.5759e-07 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 0.9969 - lr: 6.2500e-05\n",
      "Epoch 292/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 2.0081e-06 - acc: 1.0000\n",
      "Epoch 292: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.9747e-06 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 0.9969 - lr: 6.2500e-05\n",
      "Epoch 293/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 1.7315e-07 - acc: 1.0000\n",
      "Epoch 293: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.0082e-07 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 0.9969 - lr: 6.2500e-05\n",
      "Epoch 294/500\n",
      "224/235 [===========================>..] - ETA: 0s - loss: 1.8356e-07 - acc: 1.0000\n",
      "Epoch 294: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.7826e-07 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 0.9969 - lr: 6.2500e-05\n",
      "Epoch 295/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 5.1798e-05 - acc: 1.0000\n",
      "Epoch 295: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.0718e-05 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9972 - lr: 6.2500e-05\n",
      "Epoch 296/500\n",
      "234/235 [============================>.] - ETA: 0s - loss: 6.5998e-06 - acc: 1.0000\n",
      "Epoch 296: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 6.5972e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9994 - lr: 6.2500e-05\n",
      "Epoch 297/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 5.1437e-07 - acc: 1.0000\n",
      "Epoch 297: val_loss did not improve from 0.00014\n",
      "\n",
      "Epoch 297: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.0759e-07 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9994 - lr: 6.2500e-05\n",
      "Epoch 298/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 3.2298e-07 - acc: 1.0000\n",
      "Epoch 298: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 4.1575e-07 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9994 - lr: 3.1250e-05\n",
      "Epoch 299/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 3.4604e-07 - acc: 1.0000\n",
      "Epoch 299: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.4110e-07 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9994 - lr: 3.1250e-05\n",
      "Epoch 300/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 1.2376e-07 - acc: 1.0000\n",
      "Epoch 300: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.2602e-07 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9994 - lr: 3.1250e-05\n",
      "Epoch 301/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 3.1074e-07 - acc: 1.0000\n",
      "Epoch 301: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.0120e-07 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9994 - lr: 3.1250e-05\n",
      "Epoch 302/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 5.1507e-07 - acc: 1.0000\n",
      "Epoch 302: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.0617e-07 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9994 - lr: 3.1250e-05\n",
      "Epoch 303/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 1.7127e-06 - acc: 1.0000\n",
      "Epoch 303: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.6563e-06 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9994 - lr: 3.1250e-05\n",
      "Epoch 304/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 5.2752e-07 - acc: 1.0000\n",
      "Epoch 304: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.1417e-07 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9994 - lr: 3.1250e-05\n",
      "Epoch 305/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 3.7070e-07 - acc: 1.0000\n",
      "Epoch 305: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.5868e-07 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 0.9994 - lr: 3.1250e-05\n",
      "Epoch 306/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 1.6389e-07 - acc: 1.0000\n",
      "Epoch 306: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.6866e-07 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 0.9994 - lr: 3.1250e-05\n",
      "Epoch 307/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 1.8725e-07 - acc: 1.0000\n",
      "Epoch 307: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.8594e-07 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 0.9994 - lr: 3.1250e-05\n",
      "Epoch 308/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 7.2653e-07 - acc: 1.0000\n",
      "Epoch 308: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 7.1141e-07 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9994 - lr: 3.1250e-05\n",
      "Epoch 309/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 6.8065e-06 - acc: 1.0000\n",
      "Epoch 309: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 6.5737e-06 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9991 - lr: 3.1250e-05\n",
      "Epoch 310/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 5.1010e-07 - acc: 1.0000\n",
      "Epoch 310: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.0157e-07 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9991 - lr: 3.1250e-05\n",
      "Epoch 311/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 5.3656e-07 - acc: 1.0000\n",
      "Epoch 311: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.2518e-07 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9994 - lr: 3.1250e-05\n",
      "Epoch 312/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 1.3478e-07 - acc: 1.0000\n",
      "Epoch 312: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.3428e-07 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9994 - lr: 3.1250e-05\n",
      "Epoch 313/500\n",
      "235/235 [==============================] - ETA: 0s - loss: 5.6441e-05 - acc: 1.0000\n",
      "Epoch 313: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.6441e-05 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 0.9978 - lr: 3.1250e-05\n",
      "Epoch 314/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 2.0047e-07 - acc: 1.0000\n",
      "Epoch 314: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.9816e-07 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 0.9978 - lr: 3.1250e-05\n",
      "Epoch 315/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 6.8464e-06 - acc: 1.0000\n",
      "Epoch 315: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 6.6708e-06 - acc: 1.0000 - val_loss: 8.4571e-04 - val_acc: 0.9997 - lr: 3.1250e-05\n",
      "Epoch 316/500\n",
      "225/235 [===========================>..] - ETA: 0s - loss: 3.3395e-07 - acc: 1.0000\n",
      "Epoch 316: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.2679e-07 - acc: 1.0000 - val_loss: 8.1771e-04 - val_acc: 0.9997 - lr: 3.1250e-05\n",
      "Epoch 317/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 8.0737e-07 - acc: 1.0000\n",
      "Epoch 317: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 7.9034e-07 - acc: 1.0000 - val_loss: 6.0704e-04 - val_acc: 0.9997 - lr: 3.1250e-05\n",
      "Epoch 318/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 9.3470e-06 - acc: 1.0000\n",
      "Epoch 318: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 9.2638e-06 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 319/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 2.5655e-06 - acc: 1.0000\n",
      "Epoch 319: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.5127e-06 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 320/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 2.0997e-04 - acc: 0.9999\n",
      "Epoch 320: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.0630e-04 - acc: 0.9999 - val_loss: 0.0109 - val_acc: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 321/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 1.7868e-05 - acc: 1.0000\n",
      "Epoch 321: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.7480e-05 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 0.9981 - lr: 3.1250e-05\n",
      "Epoch 322/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 1.4233e-07 - acc: 1.0000\n",
      "Epoch 322: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.3987e-07 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9981 - lr: 3.1250e-05\n",
      "Epoch 323/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 1.2705e-07 - acc: 1.0000\n",
      "Epoch 323: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.2296e-07 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 0.9981 - lr: 3.1250e-05\n",
      "Epoch 324/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 1.8746e-04 - acc: 0.9999\n",
      "Epoch 324: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.8098e-04 - acc: 0.9999 - val_loss: 0.0128 - val_acc: 0.9969 - lr: 3.1250e-05\n",
      "Epoch 325/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 3.2690e-05 - acc: 1.0000\n",
      "Epoch 325: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.1981e-05 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9969 - lr: 3.1250e-05\n",
      "Epoch 326/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 1.0048e-06 - acc: 1.0000\n",
      "Epoch 326: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 9.8775e-07 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9969 - lr: 3.1250e-05\n",
      "Epoch 327/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 4.1136e-07 - acc: 1.0000\n",
      "Epoch 327: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 4.0474e-07 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9969 - lr: 3.1250e-05\n",
      "Epoch 328/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 5.8078e-07 - acc: 1.0000\n",
      "Epoch 328: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.6130e-07 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9969 - lr: 3.1250e-05\n",
      "Epoch 329/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 1.4496e-07 - acc: 1.0000\n",
      "Epoch 329: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.4346e-07 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 0.9969 - lr: 3.1250e-05\n",
      "Epoch 330/500\n",
      "232/235 [============================>.] - ETA: 0s - loss: 1.8954e-05 - acc: 1.0000\n",
      "Epoch 330: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.8785e-05 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 331/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 1.9947e-07 - acc: 1.0000\n",
      "Epoch 331: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.9491e-07 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 332/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 1.4012e-06 - acc: 1.0000\n",
      "Epoch 332: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.3659e-06 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 333/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 5.9603e-06 - acc: 1.0000\n",
      "Epoch 333: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 5.8566e-06 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 334/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 1.3395e-07 - acc: 1.0000\n",
      "Epoch 334: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.3048e-07 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 335/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 1.7271e-07 - acc: 1.0000\n",
      "Epoch 335: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.6896e-07 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 336/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 3.3412e-07 - acc: 1.0000\n",
      "Epoch 336: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.2987e-07 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 337/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 4.0908e-07 - acc: 1.0000\n",
      "Epoch 337: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.9920e-07 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 338/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 2.7512e-07 - acc: 1.0000\n",
      "Epoch 338: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.7089e-07 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 339/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 4.8209e-07 - acc: 1.0000\n",
      "Epoch 339: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 4.7265e-07 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 340/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 1.4055e-07 - acc: 1.0000\n",
      "Epoch 340: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.3750e-07 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 341/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 1.6832e-07 - acc: 1.0000\n",
      "Epoch 341: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.7143e-07 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 342/500\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 3.2728e-07 - acc: 1.0000\n",
      "Epoch 342: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 3.3076e-07 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 343/500\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 2.8341e-07 - acc: 1.0000\n",
      "Epoch 343: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.7543e-07 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 344/500\n",
      "231/235 [============================>.] - ETA: 0s - loss: 1.1189e-06 - acc: 1.0000\n",
      "Epoch 344: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.1042e-06 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 345/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 1.1636e-07 - acc: 1.0000\n",
      "Epoch 345: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.1616e-07 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 346/500\n",
      "230/235 [============================>.] - ETA: 0s - loss: 1.2023e-06 - acc: 1.0000\n",
      "Epoch 346: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.2091e-06 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 347/500\n",
      "229/235 [============================>.] - ETA: 0s - loss: 1.7846e-07 - acc: 1.0000\n",
      "Epoch 347: val_loss did not improve from 0.00014\n",
      "\n",
      "Epoch 347: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.7477e-07 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 348/500\n",
      "228/235 [============================>.] - ETA: 0s - loss: 1.7284e-07 - acc: 1.0000\n",
      "Epoch 348: val_loss did not improve from 0.00014\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.7192e-07 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 0.9972 - lr: 1.5625e-05\n",
      "Epoch 348: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=500,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/model.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'),\n",
    "        EarlyStopping(monitor='val_loss', patience=100, verbose=1, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mcw1217\\Desktop\\ \\fall_detection_paper_best\\train.ipynb  11\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mcw1217/Desktop/%EB%82%99%EC%83%81%EA%B0%90%EC%A7%80%20%EB%85%BC%EB%AC%B8/fall_detection_paper_best/train.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m fig, loss_ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(figsize\u001b[39m=\u001b[39m(\u001b[39m16\u001b[39m, \u001b[39m10\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mcw1217/Desktop/%EB%82%99%EC%83%81%EA%B0%90%EC%A7%80%20%EB%85%BC%EB%AC%B8/fall_detection_paper_best/train.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m acc_ax \u001b[39m=\u001b[39m loss_ax\u001b[39m.\u001b[39mtwinx()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mcw1217/Desktop/%EB%82%99%EC%83%81%EA%B0%90%EC%A7%80%20%EB%85%BC%EB%AC%B8/fall_detection_paper_best/train.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m loss_ax\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain loss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mcw1217/Desktop/%EB%82%99%EC%83%81%EA%B0%90%EC%A7%80%20%EB%85%BC%EB%AC%B8/fall_detection_paper_best/train.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m loss_ax\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval loss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mcw1217/Desktop/%EB%82%99%EC%83%81%EA%B0%90%EC%A7%80%20%EB%85%BC%EB%AC%B8/fall_detection_paper_best/train.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m loss_ax\u001b[39m.\u001b[39mset_xlabel(\u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('models/model.h5')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 30, 137)\n",
      "(200, 30, 137)\n"
     ]
    }
   ],
   "source": [
    "actions = [\n",
    "    'fall','stand'\n",
    "]\n",
    "data = np.load(\"dataset/raw_fall_0.npy\")\n",
    "datas = np.load(\"dataset/raw_stand_1.npy\")\n",
    "\n",
    "for i in range(1,800):\n",
    "    data = np.concatenate([\n",
    "        data,\n",
    "        np.load(f'dataset/raw_fall_{i}.npy')\n",
    "    ], axis=0)\n",
    "    \n",
    "for i in range(1,200):\n",
    "    datas = np.concatenate([\n",
    "        datas,\n",
    "        np.load(f'dataset/raw_stand_{i}.npy')\n",
    "    ], axis=0)\n",
    "    \n",
    "data = np.concatenate([data,datas])\n",
    "print(data.shape)\n",
    "print(datas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 30, 136)\n",
      "(1000,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)\n",
    "print(labels[700:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 30, 136) (900, 2)\n",
      "(100, 30, 136) (100, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=2021)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 64)                51456     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,602\n",
      "Trainable params: 53,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=x_train.shape[1:3]),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.4847 - acc: 0.7868\n",
      "Epoch 1: val_acc improved from -inf to 1.00000, saving model to models\\model.h5\n",
      "29/29 [==============================] - 1s 12ms/step - loss: 2.4737 - acc: 0.7878 - val_loss: 0.1331 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 2: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 3: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 4: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 5: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 6: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 7: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 8: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 9: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 10: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 11: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 12: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 13: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 14: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 15: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 16: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 17: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 18: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 19: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 20: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 21: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 22: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 23: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 24: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 25: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 26: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 27: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 28: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 29: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 30: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 31: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 32: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 33: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 34: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 35: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 36: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 37: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 38: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 39: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 40: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 41: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 42: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 43: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 44: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 45: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 46: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 47: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 48: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 49: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 50: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "21/29 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 51: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 52: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 53/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 53: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 54/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 54: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 55/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 55: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 56/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 56: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 57/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 57: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 58/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 58: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 59/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 59: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 60/200\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 60: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 61/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 61: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 62/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 62: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 63/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 63: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 64/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 64: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 65/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 65: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 66/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 66: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 67/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 67: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 68/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 68: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 69/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 69: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 70/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 70: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 71/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 71: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 72/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 72: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 73/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 73: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 74: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 75/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 75: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 76/200\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 76: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 77/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 77: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 78/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 78: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 79/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 79: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 80/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 80: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 81/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 81: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 82/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 82: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 83/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 83: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 84/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 84: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 85/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 85: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 86/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 86: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 87/200\n",
      "21/29 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 87: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 88/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 88: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 89/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 89: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 90/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 90: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 91/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 91: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 92/200\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 92: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 93/200\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 93: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 94/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 94: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 95/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 95: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 96/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 96: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 97/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 97: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 98/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 98: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 99/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 99: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 100/200\n",
      "21/29 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 100: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 101/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 101: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 102/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 102: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 103/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 103: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 104/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 104: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 105/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 105: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 106/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 106: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 107/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 107: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 108/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 108: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 109/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 109: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 110/200\n",
      "21/29 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 110: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 111/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 111: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 112/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 112: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 113/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 113: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 114/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 114: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 115/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 115: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 116/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 116: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 117/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 117: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 118/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 118: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 119/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 119: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 120/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 120: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 121/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 121: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 122/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 122: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 123/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 123: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 124/200\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 124: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 125/200\n",
      "21/29 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 125: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 126/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 126: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 127/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 127: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 128/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 128: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 129/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 129: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 130/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 130: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 131/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 131: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 132/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 132: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 133/200\n",
      "21/29 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 133: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 134/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 134: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 135/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 135: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 136/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 136: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 137/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 137: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 138/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 138: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 139/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 139: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 140/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 140: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 141/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 141: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 142/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 142: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 143/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 143: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 144/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 144: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 145/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 145: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 146/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 146: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 147/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 147: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 148/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 148: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 149/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 149: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 150/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 150: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 151/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 151: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 152/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 152: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 153/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 153: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 154/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 154: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 155/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 155: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 156/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 156: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 157/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 157: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 158/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 158: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 159/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 159: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 160/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 160: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 161/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 161: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 162/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 162: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 163/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 163: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 164/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 164: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 165/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 165: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 166/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 166: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 167/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 167: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 168/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 168: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 169/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 169: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 170/200\n",
      "21/29 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 170: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 171/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 171: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 172/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 172: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 173/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 173: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 174/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 174: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 175/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 175: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 176/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 176: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 177/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 177: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 178/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 178: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 179/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 179: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 180/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 180: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 181/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 181: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 182/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 182: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 183/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 183: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 184/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 184: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 185/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 185: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 186/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 186: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 187/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 187: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 188/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 188: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 189/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 189: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 190/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 190: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 191/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 191: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 192/200\n",
      "21/29 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 192: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 193/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 193: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 194/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 194: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 195/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 195: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 196/200\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 196: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 197/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 197: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 198/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 198: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 199/200\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 199: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 200/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 200: val_acc did not improve from 1.00000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=200,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[19,  0],\n",
       "        [ 0, 81]],\n",
       "\n",
       "       [[81,  0],\n",
       "        [ 0, 19]]], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('models/model.h5')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
